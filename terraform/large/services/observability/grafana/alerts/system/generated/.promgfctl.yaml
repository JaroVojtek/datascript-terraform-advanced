alerts:
  - name: kube-prometheus
    url: https://raw.githubusercontent.com/prometheus-operator/kube-prometheus/v0.12.0/manifests/kubePrometheus-prometheusRule.yaml
    groups:
      - name: general.rules
        rules:
          - name: InfoInhibitor
            enabled: false # inhibitor rules not supported in Grafana
          - name: TargetDown
            relativeTimeRange:
              from: 2m
              to: 0m
            patch:
              expr: |
                (
                  100 * (count(up == 0) by (job, namespace, service, cluster))
                  /
                  count(up) by (job, namespace, service, cluster)
                ) > 10

  - name: prometheus
    url: https://raw.githubusercontent.com/prometheus-operator/kube-prometheus/v0.12.0/manifests/prometheus-prometheusRule.yaml
    groups:
      - name: prometheus
        rules:
          - name: PrometheusErrorSendingAlertsToAnyAlertmanager
            enabled: false # we are using Grafana built-in Alertmanager
          - name: PrometheusErrorSendingAlertsToSomeAlertmanagers
            enabled: false # we are using Grafana built-in Alertmanager

  - name: prometheus-operator
    url: https://raw.githubusercontent.com/prometheus-operator/kube-prometheus/v0.12.0/manifests/prometheusOperator-prometheusRule.yaml
    groups:
      - name: prometheus-operator
        rules:
          - name: PrometheusOperatorListErrors
            patch:
              expr: |
                (
                  sum by (controller,namespace,cluster) (rate(prometheus_operator_list_operations_failed_total{job="prometheus-operator",namespace="monitoring"}[10m]))
                  /
                  sum by (controller,namespace,cluster) (rate(prometheus_operator_list_operations_total{job="prometheus-operator",namespace="monitoring"}[10m]))
                ) > 0.4
          - name: PrometheusOperatorNotReady
            patch:
              expr: |
                (
                  min by (controller,namespace,cluster) (max_over_time(prometheus_operator_ready{job="prometheus-operator",namespace="monitoring"}[5m]))
                ) == 0
          - name: PrometheusOperatorReconcileErrors
            patch:
              expr: |
                (
                  sum by (controller,namespace,cluster) (rate(prometheus_operator_reconcile_errors_total{job="prometheus-operator",namespace="monitoring"}[5m]))
                  /
                  sum by (controller,namespace,cluster) (rate(prometheus_operator_reconcile_operations_total{job="prometheus-operator",namespace="monitoring"}[5m]))
                ) > 0.1
          - name: PrometheusOperatorWatchErrors
            patch:
              expr: |
                (
                  sum by (controller,namespace,cluster) (rate(prometheus_operator_watch_operations_failed_total{job="prometheus-operator",namespace="monitoring"}[5m]))
                  /
                  sum by (controller,namespace,cluster) (rate(prometheus_operator_watch_operations_total{job="prometheus-operator",namespace="monitoring"}[5m]))
                ) > 0.4



  - name: kube-state-metrics
    url: https://raw.githubusercontent.com/prometheus-operator/kube-prometheus/v0.12.0/manifests/kubeStateMetrics-prometheusRule.yaml
    groups:
      - name: kube-state-metrics
        rules:
          - name: KubeStateMetricsListErrors
            patch:
              expr: |
                (
                  sum by (cluster) (rate(kube_state_metrics_list_total{job="kube-state-metrics",result="error"}[5m]))
                  /
                  sum by (cluster) (rate(kube_state_metrics_list_total{job="kube-state-metrics"}[5m]))
                ) > 0.01
          - name: KubeStateMetricsShardingMismatch
            patch:
              expr: |
                stdvar by (cluster) (kube_state_metrics_total_shards{job="kube-state-metrics"}) != 0
          - name: KubeStateMetricsShardsMissing
            patch:
              expr: |
                (
                  2 ^ max by (cluster) (kube_state_metrics_total_shards{job="kube-state-metrics"}) - 1
                  -
                  sum by (cluster) (2 ^ max by (cluster, shard_ordinal) (kube_state_metrics_shard_ordinal{job="kube-state-metrics"}))
                ) != 0
          - name: KubeStateMetricsWatchErrors
            patch:
              expr: |
                (
                  sum by (cluster) (rate(kube_state_metrics_watch_total{job="kube-state-metrics",result="error"}[5m]))
                  /
                  sum by (cluster) (rate(kube_state_metrics_watch_total{job="kube-state-metrics"}[5m]))
                ) > 0.01



  - name: node-exporter
    url: https://raw.githubusercontent.com/prometheus-operator/kube-prometheus/v0.12.0/manifests/nodeExporter-prometheusRule.yaml
    groups:
      - name: node-exporter
        rules:
          - name: NodeRAIDDegraded
            enabled: false # we are not using RAID arrays
          - name: NodeRAIDDiskFailure
            enabled: false # we are not using RAID arrays
          - name: NodeFilesystemSpaceFillingUp
            annotations:
              __dashboardUid__: k8s-cluster-node
              __panelId__: 202
          - name: NodeFilesystemFilesFillingUp
            annotations:
              __dashboardUid__: k8s-cluster-node
              __panelId__: 206
          - name: NodeFilesystemAlmostOutOfSpace
            annotations:
              __dashboardUid__: k8s-cluster-node
              __panelId__: 202
          - name: NodeFilesystemAlmostOutOfFiles
            annotations:
              __dashboardUid__: k8s-cluster-node
              __panelId__: 206
          - name: NodeFileDescriptorLimit
            annotations:
              __dashboardUid__: k8s-cluster-node
              __panelId__: 206
          - name: NodeNetworkReceiveErrs
            annotations:
              __dashboardUid__: k8s-cluster-node
              __panelId__: 238
          - name: NodeNetworkTransmitErrs
            annotations:
              __dashboardUid__: k8s-cluster-node
              __panelId__: 238
          - name: NodeHighNumberConntrackEntriesUsed
            annotations:
              __dashboardUid__: k8s-cluster-node
              __panelId__: 232
          - name: NodeClockSkewDetected
            annotations:
              __dashboardUid__: k8s-cluster-node
              __panelId__: 270
          - name: NodeClockNotSynchronising
            annotations:
              __dashboardUid__: k8s-cluster-node
              __panelId__: 268

  - name: kubernetes-control-plane
    url: https://raw.githubusercontent.com/prometheus-operator/kube-prometheus/v0.12.0/manifests/kubernetesControlPlane-prometheusRule.yaml
    groups:
      - name: kubernetes-apps
        rules:
          - name: KubePodCrashLooping
            patch:
              expr: |
                (
                  max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics"}[5m]) >= 1
                ) and on (cluster, namespace, pod, container) kube_pod_labels{label_monitoring_scope="system"}
          - name: KubePodNotReady
            patch:
              expr: |
                (
                  sum by (cluster, namespace, pod) (
                    max by (cluster, namespace, pod) (kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown|Failed"})
                    * on (cluster, namespace, pod) group_left(owner_kind) topk by(namespace, pod, cluster) (1, max by(namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"}))
                  ) > 0
                ) and on (cluster, namespace, pod) kube_pod_labels{label_monitoring_scope="system"}
          - name: KubeContainerWaiting
            patch:
              expr: |
                (
                  kube_pod_container_status_waiting_reason{reason="ContainerCreating"} > 0
                ) and on (cluster, namespace, pod, container) kube_pod_labels{label_monitoring_scope="system"}
          - name: KubeDeploymentGenerationMismatch
            patch:
              expr: |
                (
                  kube_deployment_status_observed_generation{job="kube-state-metrics"} != kube_deployment_metadata_generation{job="kube-state-metrics"}
                ) and on (cluster, namespace, deployment) kube_deployment_labels{label_monitoring_scope="system"}
          - name: KubeDeploymentReplicasMismatch
            patch:
              expr: |
                (
                  (
                    kube_deployment_spec_replicas{job="kube-state-metrics"} > kube_deployment_status_replicas_available{job="kube-state-metrics"}
                  ) and (
                    changes(kube_deployment_status_replicas_updated{job="kube-state-metrics"}[10m]) ==  0
                  )
                ) and on (cluster, namespace, deployment) kube_deployment_labels{label_monitoring_scope="system"}
          - name: KubeStatefulSetReplicasMismatch
            patch:
              expr: |
                (
                  (
                    kube_statefulset_status_replicas_ready{job="kube-state-metrics"} != kube_statefulset_status_replicas{job="kube-state-metrics"}
                  ) and (
                    changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[10m]) == 0
                  )
                ) and on (cluster, namespace, statefulset) kube_statefulset_labels{label_monitoring_scope="system"}
          - name: KubeStatefulSetGenerationMismatch
            patch:
              expr: |
                (
                  kube_statefulset_status_observed_generation{job="kube-state-metrics"} != kube_statefulset_metadata_generation{job="kube-state-metrics"}
                ) and on (cluster, namespace, statefulset) kube_statefulset_labels{label_monitoring_scope="system"}
          - name: KubeStatefulSetUpdateNotRolledOut
            patch:
              expr: |
                (
                  (
                    max without (revision) (kube_statefulset_status_current_revision{job="kube-state-metrics"} unless kube_statefulset_status_update_revision{job="kube-state-metrics"})
                    * (
                      kube_statefulset_replicas{job="kube-state-metrics"} != kube_statefulset_status_replicas_updated{job="kube-state-metrics"}
                    )
                  ) and (
                    changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[5m]) == 0
                  )
                ) and on (cluster, namespace, statefulset) kube_statefulset_labels{label_monitoring_scope="system"}
          - name: KubeDaemonSetRolloutStuck
            patch:
              expr: |
                (
                  (
                    (
                      kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} != kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
                    ) or (
                      kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} != 0
                    ) or (
                      kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"} != kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
                    ) or (
                      kube_daemonset_status_number_available{job="kube-state-metrics"} != kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
                    )
                  ) and (
                    changes(kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}[5m]) == 0
                  )
                ) and on (cluster, namespace, daemonset) kube_daemonset_labels{label_monitoring_scope="system"}
          - name: KubeDaemonSetNotScheduled
            patch:
              expr: |
                (
                  (
                    kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"} - kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"}
                  ) > 0
                ) and on (cluster, namespace, daemonset) kube_daemonset_labels{label_monitoring_scope="system"}
          - name: KubeDaemonSetMisScheduled
            patch:
              expr: |
                (
                  kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0
                ) and on (cluster, namespace, daemonset) kube_daemonset_labels{label_monitoring_scope="system"}
          - name: KubeJobNotCompleted
            patch:
              expr: |
                (
                  (
                    (
                      time() - max by(namespace, job_name, cluster) (kube_job_status_start_time{job="kube-state-metrics"})
                    ) and (
                      kube_job_status_active{job="kube-state-metrics"} > 0
                    )
                  ) > 43200
                ) and on (cluster, namespace, job_name) kube_job_labels{label_monitoring_scope="system"}
          - name: KubeJobFailed
            enabled: false
          - name: KubeHpaReplicasMismatch
            patch:
              expr: |
                (
                  (
                    kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics"} != kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
                  ) and (
                    kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"} > kube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics"}
                  ) and (
                    kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"} < kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"}
                  ) and (
                    changes(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}[15m]) == 0
                  )
                ) and on (cluster, namespace, horizontalpodautoscaler) kube_horizontalpodautoscaler_labels{label_monitoring_scope="system"}
          - name: KubeHpaMaxedOut
            patch:
              expr: |
                (
                  kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"} == kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"}
                ) and on (cluster, namespace, horizontalpodautoscaler) kube_horizontalpodautoscaler_labels{label_monitoring_scope="system"}
          - name: KubePersistentVolumeFillingUp
            labels:
              severity: critical
            patch:
              expr: |
                (
                  (
                    (
                      kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}
                      /
                      kubelet_volume_stats_capacity_bytes{job="kubelet", metrics_path="/metrics"}
                    ) < 0.03
                  ) and (
                    kubelet_volume_stats_used_bytes{job="kubelet", metrics_path="/metrics"} > 0
                  )
                  unless on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{access_mode="ReadOnlyMany"} == 1
                  unless on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
                ) and on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_monitoring_scope="system"}
          - name: KubePersistentVolumeFillingUp
            labels:
              severity: warning
            patch:
              expr: |
                (
                  (
                    (
                      kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}
                      /
                      kubelet_volume_stats_capacity_bytes{job="kubelet", metrics_path="/metrics"}
                    ) < 0.15
                  ) and (
                    kubelet_volume_stats_used_bytes{job="kubelet", metrics_path="/metrics"} > 0
                  ) and (
                    predict_linear(kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
                  )
                  unless on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{access_mode="ReadOnlyMany"} == 1
                  unless on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
                ) and on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_monitoring_scope="system"}
          - name: KubePersistentVolumeInodesFillingUp
            labels:
              severity: critical
            patch:
              expr: |
                (
                  (
                    (
                      kubelet_volume_stats_inodes_free{job="kubelet", metrics_path="/metrics"}
                      /
                      kubelet_volume_stats_inodes_free{job="kubelet", metrics_path="/metrics"}
                    ) < 0.03
                  ) and (
                    kubelet_volume_stats_inodes_used{job="kubelet", metrics_path="/metrics"} > 0
                  )
                  unless on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{access_mode="ReadOnlyMany"} == 1
                  unless on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
                ) and on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_monitoring_scope="system"}
          - name: KubePersistentVolumeInodesFillingUp
            labels:
              severity: warning
            patch:
              expr: |
                (
                  (
                    (
                      kubelet_volume_stats_inodes_free{job="kubelet", metrics_path="/metrics"}
                      /
                      kubelet_volume_stats_inodes_free{job="kubelet", metrics_path="/metrics"}
                    ) < 0.15
                  ) and (
                    kubelet_volume_stats_inodes_used{job="kubelet", metrics_path="/metrics"} > 0
                  ) and (
                    predict_linear(kubelet_volume_stats_inodes_free{job="kubelet", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
                  )
                  unless on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{access_mode="ReadOnlyMany"} == 1
                  unless on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
                ) and on (cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_monitoring_scope="system"}




      - name: kubernetes-resources
        rules:
          - name: KubeCPUOvercommit
            patch:
              expr: |
                (
                  sum by (cluster, namespace) (namespace_cpu:kube_pod_container_resource_requests:sum{}) - (sum by (cluster) (kube_node_status_allocatable{resource="cpu"}) - max by (cluster) (kube_node_status_allocatable{resource="cpu"})
                ) > 0
                and
                (
                  sum by (cluster, namespace) (kube_node_status_allocatable{resource="cpu"}) - max by (cluster) (kube_node_status_allocatable{resource="cpu"}))
                ) > 0
          - name: KubeCPUQuotaOvercommit
            patch:
              expr: |
                (
                  sum by (cluster, namespace) (min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(cpu|requests.cpu)"}))
                  /
                  sum by (cluster, namespace) (kube_node_status_allocatable{resource="cpu", job="kube-state-metrics"})
                ) > 1.5
          - name: KubeMemoryOvercommit
            patch:
              expr: |
                (
                  sum by (cluster, namespace) (namespace_memory:kube_pod_container_resource_requests:sum{}) - (sum by (cluster) (kube_node_status_allocatable{resource="memory"}) - max by (cluster) (kube_node_status_allocatable{resource="memory"}))
                ) > 0
                and
                (
                  sum by (cluster, namespace) (kube_node_status_allocatable{resource="memory"}) - max by (cluster) (kube_node_status_allocatable{resource="memory"})
                ) > 0
          - name: KubeMemoryQuotaOvercommit
            patch:
              expr: |
                (
                  sum by (cluster, namespace) (min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(memory|requests.memory)"}))
                  /
                  sum by (cluster, namespace) (kube_node_status_allocatable{resource="memory", job="kube-state-metrics"})
                ) > 1.5
          - name: CPUThrottlingHigh
            patch:
              expr: |
                (
                  sum (increase(container_cpu_cfs_throttled_periods_total{container!="", }[5m])) by (container, pod, namespace, cluster)
                  /
                  sum(increase(container_cpu_cfs_periods_total{}[5m])) by (container, pod, namespace, cluster)
                ) > (25 / 100)



      - name: kubernetes-system-apiserver
        rules:
          - name: KubeAPITerminatedRequests
            patch:
              expr: |
                (
                  sum by (cluster) (rate(apiserver_request_terminations_total{job="apiserver"}[10m]))
                  /
                  (
                    sum by(cluster) (rate(apiserver_request_total{job="apiserver"}[10m]))
                    +
                    sum by(cluster) (rate(apiserver_request_terminations_total{job="apiserver"}[10m]))
                  )
                ) > 0.20
      - name: kubernetes-system-kubelet
        rules:
          - name: KubeletClientCertificateExpiration
            enabled: false # metric is not exposed by EKS
          - name: KubeletClientCertificateRenewalErrors
            enabled: false # metric is not exposed by EKS
      - name: kubernetes-system-scheduler
        enabled: false # metrics are not exposed by EKS
      - name: kubernetes-system-controller-manager
        enabled: false # metrics are not exposed by EKS
